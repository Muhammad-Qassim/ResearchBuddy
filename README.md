# ğŸ“š ResearchBuddy AI

**ResearchBuddy AI** is a full-stack intelligent assistant that simplifies academic exploration by providing AI-powered summarization, topic understanding, and contextual Q&A. Built for students, researchers, and curious minds looking to make sense of complex technical content without drowning in information overload.

---

## ğŸš€ Overview

ResearchBuddy supports:
- Summarizing long research papers (up to 16K+ tokens)
- Auto-analyzing GitHub repositories
- Exploring structured Wikipedia topic overviews
- Chatting with a RAG-based assistant trained on 300K+ STEM Q&A pairs (and growing)
- Intelligent search with support for natural language queries

---

## ğŸ§© Key Features

| Module | Description |
|--------|-------------|
| ğŸ“ **Paper Summarizer** | Fine-tuned LongT5 model provides structured summaries (objective, method, findings, conclusion). |
| ğŸ’» **GitHub Summarizer** | Gemini-powered summaries for `README.md` files and project intros. |
| ğŸŒ **Wikipedia Explorer** | Retrieves clean intros and related topics via OpenAlex + Wikidata. |
| ğŸ¤– **RAG Chatbot** | Contextual question-answering using 300K+ STEM entries from GitHub, StackExchange, and papers. |
| ğŸ’¬ **Search + Query Handling** | Query expansion and smart ranking via vector search in Qdrant. |

---

## ğŸ› ï¸ Tech Stack

| Layer | Tools |
|-------|-------|
| Frontend | React + Material UI (MUI), custom components |
| Backend | Flask API |
| AI Models | `google/long-t5-tglobal-xl` (QLoRA + DeepSpeed Stage 3), `flan-t5-large`  , `mistral 7b` |
| Embeddings | Sentence Transformers |
| Vector DB | Qdrant |
| Deployment | Docker, Docker Compose, GCP L4 VM, Vast.ai RTX 8000 |
| Data APIs | OpenAlex, Gemini, Wikipedia, Semantic Scholar |

---

## ğŸ§ª Training & Evaluation

| Detail | Info |
|--------|------|
| Input Length | 16,384 tokens |
| Training Infra | 2Ã— A100 GPUs using DeepSpeed Stage 3 |
| Dataset | 1000+ ArXiv summaries |
| Evaluation | ROUGE |

---

## ğŸ§  RAG System Architecture

```
User Query â†’ Embedding â†’ Qdrant Search â†’ Top-k Results â†’ Prompted Context â†’ Final LLM Answer
```

Uses 300K+ Q&A entries and supports expansion to 500K+ entries for improved retrieval accuracy.

---

## ğŸ—‚ï¸ Project Structure

```
ResearchBuddy/
â”œâ”€â”€ backend/              # Flask backend with modular folders
â”‚   â”œâ”€â”€ Chatbot/          # RAG logic & Gemini prompts
â”‚   â”œâ”€â”€ Github/           # GitHub summarization
â”‚   â”œâ”€â”€ MongoDB/          # MongoDB connection layer
â”‚   â”œâ”€â”€ Overview/         # Wikipedia/OpenAlex retriever
â”‚   â”œâ”€â”€ Qdrant/           # Vector DB setup + upsertion scripts
â”‚   â”œâ”€â”€ ResearchPaper/    # ArXiv, summarizer, PDF handling
â”‚   â”œâ”€â”€ Youtube/          # Placeholder YouTube integration
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ frontend/             # React + MUI UI
â”‚   â””â”€â”€ src/components/   # Buddy, GitHub, Wikipedia, Search, Layout, etc.
â”œâ”€â”€ Phase-1+2+3/          # Notebooks and experiment logs
â”‚   â”œâ”€â”€ data/             # JSON dataset
â”‚   â””â”€â”€ src/              # All training notebooks
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“¸ Screenshots

- HomePage
![image](/Phase-1+2+3/Screenshots/homepage.png)
- Summary result cards
![image](/Phase-1+2+3/Screenshots/paper.png)
- GitHub repo summarizer
![image](/Phase-1+2+3/Screenshots/overview.png)
- RAG chatbot in action
![image](/Phase-1+2+3/Screenshots/rag.png)
![image](/Phase-1+2+3/Screenshots/github.png)
- Wikipedia topic page

---

## ğŸ³ Deployment

This project uses Docker for both frontend and backend containers.  
Run locally with:

```bash
docker-compose up --build
```

Make sure `.env` files are set in both `/frontend` and `/backend`.

---

## ğŸ™ Acknowledgments

- My capstone supervisor and faculty mentors  
- The open-source community and contributors to Qdrant, Hugging Face, and Semantic Scholar

---

## ğŸ“¬ Contact

**Muhammad Qassim**  
[LinkedIn](https://www.linkedin.com/in/muhammad-qassim/) | [Email](muhammad@qassim.dev)
