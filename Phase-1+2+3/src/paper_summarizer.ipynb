{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from pdfminer.high_level import extract_text\n",
    "import os\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"semantic segmentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Papers\n",
    "Function to Fetch ArXiv Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_arxiv_papers(query):\n",
    "    \"\"\"\"\n",
    "    Fetches the arXiv papers for the given query\n",
    "\n",
    "    Args:\n",
    "        query (str): The query to search arXiv for papers\n",
    "        \n",
    "    Returns:\n",
    "        pdf_links (list): List of pdf links for the papers\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query={query}&start=0&max_results=1\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch data from arXiv\")\n",
    "        return []\n",
    "\n",
    "    root = ET.fromstring(response.text)\n",
    "    pdf_links = []\n",
    "    for entry in root.findall(\"{http://www.w3.org/2005/Atom}entry\"):\n",
    "        for link in entry.findall(\"{http://www.w3.org/2005/Atom}link\"):\n",
    "            if link.attrib.get(\"title\") == \"pdf\":\n",
    "                pdf_links.append(link.attrib[\"href\"])\n",
    "\n",
    "    return pdf_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch PDF Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDF link: http://arxiv.org/pdf/2304.10326v1\n"
     ]
    }
   ],
   "source": [
    "pdf_links = fetch_arxiv_papers(query)\n",
    "if pdf_links:\n",
    "    print(f\"Found PDF link: {pdf_links[0]}\")\n",
    "else:\n",
    "    print(\"No PDF links found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download PDF File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF saved to 1.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_file = \"1.pdf\"\n",
    "\n",
    "response = requests.get(pdf_links[0])\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(pdf_file, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"PDF saved to {pdf_file}\")\n",
    "else:\n",
    "    print(\"Failed to fetch PDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"1.pdf\"\n",
    "text = extract_text(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: T5-small\n",
    "Loading the fine-tuned T5-small model for summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = T5ForConditionalGeneration.from_pretrained(\"../practice/t5-small-finetuned-arxiv\")\n",
    "model_checkpoint1 = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarization Function for T5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_summary_t5_small(input_text):\n",
    "    \"\"\"\n",
    "    Generates a summary for the given input text using the T5 small model\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input text to summarize\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        \"summarize: \" + input_text,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    outputs = model1.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: FLAN-T5-base\n",
    "Load the PEFT-tuned FLAN-T5-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\muham\\Desktop\\delete\\practice\\.venv\\Lib\\site-packages\\peft\\peft_model.py:157: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  adapters_weights = torch.load(\n"
     ]
    }
   ],
   "source": [
    "peft_model_id = \"../practice/lora-flan-t5-base/model\" \n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "model2 = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    device_map=\"auto\" \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "model2 = PeftModel.from_pretrained(model2, peft_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Summarization Function for FLAN-T5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_summary_FLAN_T5_base(input_text):\n",
    "    \"\"\"\n",
    "    Generates a summary for the given input text using the FLAN T5 base model\n",
    "\n",
    "    Args:\n",
    "        input_text (str): The input text to summarize\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        \"summarize: \" + input_text,\n",
    "        max_length=1024,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model2.device)\n",
    "\n",
    "    outputs = model2.generate(\n",
    "        input_ids=inputs.input_ids, \n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Summaries Using Both Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_t5_small = test_summary_t5_small(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_FLAN_T5_base = test_summary_FLAN_T5_base(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print Generated Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary from T5-small: in this technical report, we demonstrate our solution for 2019 COCO panoptic segmentation task. we use instance segmentation and semantic segmen- tation as a method which performs the s c in- stance and semantic segmen- tation separately, then combines the two to generate panop-tic segmentation results. our technique performs the instance segmentation and semantic segmen- tation separately, then combines the two to generate panop-tic segmentation results. to facilitate the results in this results, we use the same way as we have achieved an impressive re- sult, we compare the results of\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summary from T5-small: {summary_t5_small}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary from FLAN-T5-base: **Main Research Objective:** To develop a joint COCO/Mapillary Workshop strategy for the 2019 COCO panoptic segmentation challenge. **Methodology:** * Created a dynamic model, Mask R-CNN, to extract the pixel-level category labels of a given image. * Recommendations to a network architecture for mask segmentation and semantic segmentation. * Contested several combinations of in-stance and semantic segmentation to achieve a strong performance. **Key Findings:** * Mask R-CNN was the best model for in-stance segmentation. * Mask R-CNN extended fast R-CNN (Fast R-CNN) to achieve the highest possible performance. * HTC model provided the best in-stance segmentation results for both the mask segmentation task and the semantic segmentation task. * The combined model was optimized for the best results on the Coco-Mapillary Workshop dataset. * The model achieved an optimal performance in the Coco-Mapillary Workshop task, achieving an overall performance of 47.1 based on Coco-Mapillary Workshop data. **Conclusions:** * The proposed approach improved the accuracy of the task by using an ensemble strategy. * It combined features of mask segmentation with semantic segmentation to create superior performance on the Coco-Mapillary Workshop dataset. * The ensemble strategy significantly enhanced the segmentation performance. * The model obtained the best in-stance segmentation result for the Coco-Mapillary Workshop dataset.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summary from FLAN-T5-base: {summary_FLAN_T5_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup: Remove Downloaded PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(pdf_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
